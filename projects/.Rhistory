expr = paste("length~", paste(colnames(data)[po.ind] , collapse = "+"))
forward.change(newdata, expr,TRUE)
kfolds.cv <- function(dat, expr){
kfolds=10
mspe = rep(0, kfolds)
ind = rep(1:kfolds, length=nrow(dat))
for(ii in 1:kfolds) {
train<- which(ind!=ii) # training observations
M.cv <- lm(expr, data=data[train,])
# cross-validation residuals
M.res <- dat$length[-train] - # test observations
predict(M.cv, newdat = dat[-train,]) # prediction with training dat
# mspe
mspe[ii] <- mean(M.res^2)
}
mean(mspe)
}
forward.change = function(data, expr, show=FALSE){
model = lm(expr, data=newdata)
initial.colname = names( model$coefficients)[-1]
tempnames = colnames(data)
cv.hist=c()
aic.hist = c()
coef.hist = list()
j=0
models = list()
while (TRUE) {
j=j+1
print(paste("step", j))
cov.in.m = colnames(model$model)
cov.all = colnames(newdata)
names.to.try = cov.all[! cov.all %in% cov.in.m]
nn = length(names.to.try)
#update tracks
cv.hist[j]=kfolds.cv(newdata, expr)
aic.hist[j] = extractAIC(model)[2]
coef.hist[[j]] = coef(model)
cv.score = rep(0, nn)
if(length(names.to.try) == 0){
print("chose all ")
break
}
for (i in 1:nn) {
name = names.to.try[i]
newexpr =   paste(expr,  "+", name )
newmodel = lm(newexpr, data=newdata)
cv.score[i] = kfolds.cv(newdata, newexpr)
}
ind = which.min(cv.score)
if(cv.score[ind]>cv.hist[j]){
print ("done choosing model")
break
}else{
# update our model
print(paste("added", names.to.try[ind]))
expr = paste(expr,"+", names.to.try[ind])
model =  lm(expr, data=newdata)
models[[j]] = model
}
}
plot(cv.hist, main = "cv")
plot(aic.hist, main = "aic")
i = length(initial.colname)
j = length(coef.hist)
M = matrix(0, nrow = i, ncol = j)
for (ii in 1:i){
for (jj in 1:j) {
M[ii,jj] =  coef.hist[[jj]][initial.colname[ii]]
}
}
if(show==TRUE){
par(mar=c(5.1,4.1,4.1,8.1), xpd=TRUE, cex=0.5)
plot(M[1,], main=initial.colname[[1]], type = 'l', col=1, ylim = range(M))
for (a in 2:i){
lines(1:j, M[a,] ,col=a)
}
legend("topright",legend = initial.colname, col = 1:i, inset=c(-0.2,0))
}
return(list(cv=cv.hist, coef=coef.hist, aic=aic.hist))
}
# forward start from length over pollutants
expr = paste("length~", paste(colnames(data)[po.ind] , collapse = "+"))
forward.change(newdata, expr,TRUE)
kfolds.cv <- function(dat, expr){
kfolds=10
mspe = rep(0, kfolds)
ind = rep(1:kfolds, length=nrow(dat))
for(ii in 1:kfolds) {
train<- which(ind!=ii) # training observations
M.cv <- lm(expr, data=data[train,])
# cross-validation residuals
M.res <- dat$length[-train] - # test observations
predict(M.cv, newdat = dat[-train,]) # prediction with training dat
# mspe
mspe[ii] <- mean(M.res^2)
}
mean(mspe)
}
forward.change = function(data, expr, show=FALSE){
model = lm(expr, data=newdata)
initial.colname = names( model$coefficients)[-1]
tempnames = colnames(data)
cv.hist=c()
aic.hist = c()
coef.hist = list()
j=0
models = list()
while (TRUE) {
j=j+1
print(paste("step", j))
cov.in.m = colnames(model$model)
cov.all = colnames(newdata)
names.to.try = cov.all[! cov.all %in% cov.in.m]
nn = length(names.to.try)
#update tracks
cv.hist[j]=kfolds.cv(newdata, expr)
aic.hist[j] = extractAIC(model)[2]
coef.hist[[j]] = coef(model)
cv.score = rep(0, nn)
if(length(names.to.try) == 0){
print("chose all ")
break
}
for (i in 1:nn) {
name = names.to.try[i]
newexpr =   paste(expr,  "+", name )
newmodel = lm(newexpr, data=newdata)
cv.score[i] = kfolds.cv(newdata, newexpr)
}
ind = which.min(cv.score)
if(cv.score[ind]>cv.hist[j]){
print ("done choosing model")
break
}else{
# update our model
print(paste("added", names.to.try[ind]))
expr = paste(expr,"+", names.to.try[ind])
model =  lm(expr, data=newdata)
models[[j]] = model
}
}
plot(cv.hist, main = "cv")
plot(aic.hist, main = "aic")
i = length(initial.colname)
j = length(coef.hist)
M = matrix(0, nrow = i, ncol = j)
for (ii in 1:i){
for (jj in 1:j) {
M[ii,jj] =  coef.hist[[jj]][initial.colname[ii]]
}
}
if(show==TRUE){
par(mar=c(5.1,4.1,4.1,8.1), xpd=TRUE, cex=0.5)
plot(M[1,], main=initial.colname[[1]], type = 'l', col=1, ylim = range(M))
for (a in 2:i){
lines(1:j, M[a,] ,col=a)
}
legend("topright",legend = initial.colname, col = 1:i)
}
return(list(cv=cv.hist, coef=coef.hist, aic=aic.hist))
}
# forward start from length over pollutants
expr = paste("length~", paste(colnames(data)[po.ind] , collapse = "+"))
forward.change(newdata, expr,TRUE)
kfolds.cv <- function(dat, expr){
kfolds=10
mspe = rep(0, kfolds)
ind = rep(1:kfolds, length=nrow(dat))
for(ii in 1:kfolds) {
train<- which(ind!=ii) # training observations
M.cv <- lm(expr, data=data[train,])
# cross-validation residuals
M.res <- dat$length[-train] - # test observations
predict(M.cv, newdat = dat[-train,]) # prediction with training dat
# mspe
mspe[ii] <- mean(M.res^2)
}
mean(mspe)
}
forward.change = function(data, expr, show=FALSE){
model = lm(expr, data=newdata)
initial.colname = names( model$coefficients)[-1]
tempnames = colnames(data)
cv.hist=c()
aic.hist = c()
coef.hist = list()
j=0
models = list()
while (TRUE) {
j=j+1
print(paste("step", j))
cov.in.m = colnames(model$model)
cov.all = colnames(newdata)
names.to.try = cov.all[! cov.all %in% cov.in.m]
nn = length(names.to.try)
#update tracks
cv.hist[j]=kfolds.cv(newdata, expr)
aic.hist[j] = extractAIC(model)[2]
coef.hist[[j]] = coef(model)
cv.score = rep(0, nn)
if(length(names.to.try) == 0){
print("chose all ")
break
}
for (i in 1:nn) {
name = names.to.try[i]
newexpr =   paste(expr,  "+", name )
newmodel = lm(newexpr, data=newdata)
cv.score[i] = kfolds.cv(newdata, newexpr)
}
ind = which.min(cv.score)
if(cv.score[ind]>cv.hist[j]){
print ("done choosing model")
break
}else{
# update our model
print(paste("added", names.to.try[ind]))
expr = paste(expr,"+", names.to.try[ind])
model =  lm(expr, data=newdata)
models[[j]] = model
}
}
plot(cv.hist, main = "cv")
plot(aic.hist, main = "aic")
i = length(initial.colname)
j = length(coef.hist)
M = matrix(0, nrow = i, ncol = j)
for (ii in 1:i){
for (jj in 1:j) {
M[ii,jj] =  coef.hist[[jj]][initial.colname[ii]]
}
}
if(show==TRUE){
par(cex=0.5)
plot(M[1,], main=initial.colname[[1]], type = 'l', col=1, ylim = range(M))
for (a in 2:i){
lines(1:j, M[a,] ,col=a)
}
legend("topright",legend = initial.colname, col = 1:i)
}
return(list(cv=cv.hist, coef=coef.hist, aic=aic.hist))
}
# forward start from length over pollutants
expr = paste("length~", paste(colnames(data)[po.ind] , collapse = "+"))
forward.change(newdata, expr,TRUE)
kfolds.cv <- function(dat, expr){
kfolds=10
mspe = rep(0, kfolds)
ind = rep(1:kfolds, length=nrow(dat))
for(ii in 1:kfolds) {
train<- which(ind!=ii) # training observations
M.cv <- lm(expr, data=data[train,])
# cross-validation residuals
M.res <- dat$length[-train] - # test observations
predict(M.cv, newdat = dat[-train,]) # prediction with training dat
# mspe
mspe[ii] <- mean(M.res^2)
}
mean(mspe)
}
forward.change = function(data, expr, show=FALSE){
model = lm(expr, data=newdata)
initial.colname = names( model$coefficients)[-1]
tempnames = colnames(data)
cv.hist=c()
aic.hist = c()
coef.hist = list()
j=0
models = list()
while (TRUE) {
j=j+1
print(paste("step", j))
cov.in.m = colnames(model$model)
cov.all = colnames(newdata)
names.to.try = cov.all[! cov.all %in% cov.in.m]
nn = length(names.to.try)
#update tracks
cv.hist[j]=kfolds.cv(newdata, expr)
aic.hist[j] = extractAIC(model)[2]
coef.hist[[j]] = coef(model)
cv.score = rep(0, nn)
if(length(names.to.try) == 0){
print("chose all ")
break
}
for (i in 1:nn) {
name = names.to.try[i]
newexpr =   paste(expr,  "+", name )
newmodel = lm(newexpr, data=newdata)
cv.score[i] = kfolds.cv(newdata, newexpr)
}
ind = which.min(cv.score)
if(cv.score[ind]>cv.hist[j]){
print ("done choosing model")
break
}else{
# update our model
print(paste("added", names.to.try[ind]))
expr = paste(expr,"+", names.to.try[ind])
model =  lm(expr, data=newdata)
models[[j]] = model
}
}
plot(cv.hist, main = "cv")
plot(aic.hist, main = "aic")
i = length(initial.colname)
j = length(coef.hist)
M = matrix(0, nrow = i, ncol = j)
for (ii in 1:i){
for (jj in 1:j) {
M[ii,jj] =  coef.hist[[jj]][initial.colname[ii]]
}
}
if(show==TRUE){
par(cex=0.5)
plot(M[1,], main=initial.colname[[1]], type = 'l', col=1, ylim = range(M))
for (a in 2:i){
lines(1:j, M[a,] ,col=a)
}
legend("topleft",legend = initial.colname, col = 1:i)
}
return(list(cv=cv.hist, coef=coef.hist, aic=aic.hist))
}
kfolds.cv <- function(dat, expr){
kfolds=10
mspe = rep(0, kfolds)
ind = rep(1:kfolds, length=nrow(dat))
for(ii in 1:kfolds) {
train<- which(ind!=ii) # training observations
M.cv <- lm(expr, data=data[train,])
# cross-validation residuals
M.res <- dat$length[-train] - # test observations
predict(M.cv, newdat = dat[-train,]) # prediction with training dat
# mspe
mspe[ii] <- mean(M.res^2)
}
mean(mspe)
}
forward.change = function(data, expr, show=FALSE){
model = lm(expr, data=newdata)
initial.colname = names( model$coefficients)[-1]
tempnames = colnames(data)
cv.hist=c()
aic.hist = c()
coef.hist = list()
j=0
models = list()
while (TRUE) {
j=j+1
print(paste("step", j))
cov.in.m = colnames(model$model)
cov.all = colnames(newdata)
names.to.try = cov.all[! cov.all %in% cov.in.m]
nn = length(names.to.try)
#update tracks
cv.hist[j]=kfolds.cv(newdata, expr)
aic.hist[j] = extractAIC(model)[2]
coef.hist[[j]] = coef(model)
cv.score = rep(0, nn)
if(length(names.to.try) == 0){
print("chose all ")
break
}
for (i in 1:nn) {
name = names.to.try[i]
newexpr =   paste(expr,  "+", name )
newmodel = lm(newexpr, data=newdata)
cv.score[i] = kfolds.cv(newdata, newexpr)
}
ind = which.min(cv.score)
if(cv.score[ind]>cv.hist[j]){
print ("done choosing model")
break
}else{
# update our model
print(paste("added", names.to.try[ind]))
expr = paste(expr,"+", names.to.try[ind])
model =  lm(expr, data=newdata)
models[[j]] = model
}
}
plot(cv.hist, main = "cv")
plot(aic.hist, main = "aic")
i = length(initial.colname)
j = length(coef.hist)
M = matrix(0, nrow = i, ncol = j)
for (ii in 1:i){
for (jj in 1:j) {
M[ii,jj] =  coef.hist[[jj]][initial.colname[ii]]
}
}
if(show==TRUE){
#par(cex=0.5)
plot(M[1,], main=initial.colname[[1]], type = 'l', col=1, ylim = range(M))
for (a in 2:i){
lines(1:j, M[a,] ,col=a)
}
legend("topleft",legend = initial.colname, col = 1:i)
}
return(list(cv=cv.hist, coef=coef.hist, aic=aic.hist))
}
# start from over ageyrs
expr = "length~ageyrs"
forward.change(newdata, expr)
# forward start from length over pollutants
expr = paste("length~", paste(colnames(data)[po.ind] , collapse = "+"))
forward.change(newdata, expr,TRUE)
kfolds.cv <- function(dat, expr){
kfolds=10
mspe = rep(0, kfolds)
ind = rep(1:kfolds, length=nrow(dat))
for(ii in 1:kfolds) {
train<- which(ind!=ii) # training observations
M.cv <- lm(expr, data=data[train,])
# cross-validation residuals
M.res <- dat$length[-train] - # test observations
predict(M.cv, newdat = dat[-train,]) # prediction with training dat
# mspe
mspe[ii] <- mean(M.res^2)
}
mean(mspe)
}
forward.change = function(data, expr, show=FALSE){
model = lm(expr, data=newdata)
initial.colname = names( model$coefficients)[-1]
tempnames = colnames(data)
cv.hist=c()
aic.hist = c()
coef.hist = list()
j=0
models = list()
while (TRUE) {
j=j+1
print(paste("step", j))
cov.in.m = colnames(model$model)
cov.all = colnames(newdata)
names.to.try = cov.all[! cov.all %in% cov.in.m]
nn = length(names.to.try)
#update tracks
cv.hist[j]=kfolds.cv(newdata, expr)
aic.hist[j] = extractAIC(model)[2]
coef.hist[[j]] = coef(model)
cv.score = rep(0, nn)
if(length(names.to.try) == 0){
print("chose all ")
break
}
for (i in 1:nn) {
name = names.to.try[i]
newexpr =   paste(expr,  "+", name )
newmodel = lm(newexpr, data=newdata)
cv.score[i] = kfolds.cv(newdata, newexpr)
}
ind = which.min(cv.score)
if(cv.score[ind]>cv.hist[j]){
print ("done choosing model")
break
}else{
# update our model
print(paste("added", names.to.try[ind]))
expr = paste(expr,"+", names.to.try[ind])
model =  lm(expr, data=newdata)
models[[j]] = model
}
}
plot(cv.hist, main = "cv")
plot(aic.hist, main = "aic")
i = length(initial.colname)
j = length(coef.hist)
M = matrix(0, nrow = i, ncol = j)
for (ii in 1:i){
for (jj in 1:j) {
M[ii,jj] =  coef.hist[[jj]][initial.colname[ii]]
}
}
if(show==TRUE){
par(cex=0.7)
plot(M[1,], main=initial.colname[[1]], type = 'l', col=1, ylim = range(M))
for (a in 2:i){
lines(1:j, M[a,] ,col=a)
}
legend("topleft",legend = initial.colname, col = 1:i)
}
return(list(cv=cv.hist, coef=coef.hist, aic=aic.hist))
}
# log transform
newdata=data
newdata[,po.ind] = log(newdata[,po.ind])
# forward start from length over pollutants
expr = paste("length~", paste(colnames(data)[po.ind] , collapse = "+"))
forward.change(newdata, expr,TRUE)
# start from over ageyrs
expr = "length~ageyrs"
forward.change(newdata, expr)
# start from choosen pollutens
chosen.pos = colnames(data) [chosen.po.ind]
expr = paste("length~", paste(chosen.pos, collapse = "+"))
t=forward.change(newdata, expr)
chosen.pos = colnames(data) [chosen.po.ind]
expr = paste("length~", paste(chosen.pos, collapse = "+"))
t=forward.change(newdata, expr, TRUE)
# forward start from lm(length~1) done
# chosen pollute + other by forward done
# error analysis
# visualize the smoke stuff
# how the coefficients vary
# log transform
newdata=data
newdata[,po.ind] = log(newdata[,po.ind])
# forward start from length over pollutants
expr = paste("length~", paste(colnames(data)[po.ind] , collapse = "+"))
forward.change(newdata, expr,TRUE)
